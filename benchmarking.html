
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>NumPy benchmarks &#8212; NumPy v1.21.dev0 Manual</title>
    
  <link rel="stylesheet" href="_static/css/index.f658d18f9b420779cfdf24aa0a7e2d77.css">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="_static/basic.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/graphviz.css" />
    
  <link rel="preload" as="script" href="_static/js/index.d3f166471bb80abb5163.js">

    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Releasing a Version" href="dev/releasing.html" />
    <link rel="prev" title="Advanced debugging tools" href="dev/development_advanced_debugging.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
<link rel="stylesheet" href="_static/numpy.css" type="text/css" />

    <!-- PR #17220: This is added via javascript in versionwarning.js  -->
    <!-- link rel="canonical" href="http://numpy.org/doc/stable/benchmarking.html" / -->


  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main">
<div class="container-xl">

    <a class="navbar-brand" href="contents.html">
    
      <img src="_static/numpylogo.svg" class="logo" alt="logo" />
    
    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-menu" aria-controls="navbar-menu" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar-menu" class="col-lg-9 collapse navbar-collapse">
      <ul id="navbar-main-elements" class="navbar-nav mr-auto">
        
        
        <li class="nav-item ">
            <a class="nav-link" href="user/index.html">User Guide</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="reference/index.html">API reference</a>
        </li>
        
        <li class="nav-item active">
            <a class="nav-link" href="dev/index.html">Development</a>
        </li>
        
        
      </ul>


      

      <ul class="navbar-nav">
        
          <li class="nav-item">
            <a class="nav-link" href="https://github.com/numpy/numpy" target="_blank" rel="noopener">
              <span><i class="fab fa-github-square"></i></span>
            </a>
          </li>
        
        
          <li class="nav-item">
            <a class="nav-link" href="https://twitter.com/numpy_team" target="_blank" rel="noopener">
              <span><i class="fab fa-twitter-square"></i></span>
            </a>
          </li>
        
      </ul>
    </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
          <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">

    <div class="bd-toc-item active">
    
  
    <ul class="nav bd-sidenav">
        
        
        
        
        
        
          
            
                <li class="">
                    <a href="dev/gitwash/index.html">Git Basics</a>
                </li>
            
          
            
                <li class="">
                    <a href="dev/development_environment.html">Setting up and using your development environment</a>
                </li>
            
          
            
                <li class="">
                    <a href="dev/development_workflow.html">Development workflow</a>
                </li>
            
          
            
                <li class="">
                    <a href="dev/development_advanced_debugging.html">Advanced debugging tools</a>
                </li>
            
          
            
                <li class="active">
                    <a href="">NumPy benchmarks</a>
                </li>
            
          
            
                <li class="">
                    <a href="https://numpy.org/neps/nep-0045-c_style_guide.html">NumPy C style guide</a>
                </li>
            
          
            
                <li class="">
                    <a href="dev/releasing.html">Releasing a Version</a>
                </li>
            
          
            
                <li class="">
                    <a href="dev/governance/index.html">NumPy governance</a>
                </li>
            
          
            
                <li class="">
                    <a href="dev/howto-docs.html">How to contribute to the NumPy documentation</a>
                </li>
            
          
        
        
      </ul>
  
  </nav>
          </div>
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
              
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="nav section-nav flex-column">
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#usage" class="nav-link">Usage</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#writing-benchmarks" class="nav-link">Writing benchmarks</a>
        </li>
    
    </ul>
</nav>


              
          </div>
          

          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <div class="section" id="numpy-benchmarks">
<h1>NumPy benchmarks<a class="headerlink" href="#numpy-benchmarks" title="Permalink to this headline">¶</a></h1>
<p>Benchmarking NumPy with Airspeed Velocity.</p>
<div class="section" id="usage">
<h2>Usage<a class="headerlink" href="#usage" title="Permalink to this headline">¶</a></h2>
<p>Airspeed Velocity manages building and Python virtualenvs by itself,
unless told otherwise. Some of the benchmarking features in
<code class="docutils literal notranslate"><span class="pre">runtests.py</span></code> also tell ASV to use the NumPy compiled by
<code class="docutils literal notranslate"><span class="pre">runtests.py</span></code>. To run the benchmarks, you do not need to install a
development version of NumPy to your current Python environment.</p>
<p>Before beginning, ensure that <em>airspeed velocity</em> is installed.
By default, <em class="xref py py-obj">asv</em> ships with support for anaconda and virtualenv:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="n">asv</span>
<span class="n">pip</span> <span class="n">install</span> <span class="n">virtualenv</span>
</pre></div>
</div>
<p>After contributing new benchmarks, you should test them locally
before submitting a pull request.</p>
<p>To run all benchmarks, navigate to the root NumPy directory at
the command line and execute:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="n">runtests</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">bench</span>
</pre></div>
</div>
<p>where <code class="docutils literal notranslate"><span class="pre">--bench</span></code> activates the benchmark suite instead of the
test suite. This builds NumPy and runs  all available benchmarks
defined in <code class="docutils literal notranslate"><span class="pre">benchmarks/</span></code>. (Note: this could take a while. Each
benchmark is run multiple times to measure the distribution in
execution times.)</p>
<p>To run benchmarks from a particular benchmark module, such as
<code class="docutils literal notranslate"><span class="pre">bench_core.py</span></code>, simply append the filename without the extension:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="n">runtests</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">bench</span> <span class="n">bench_core</span>
</pre></div>
</div>
<p>To run a benchmark defined in a class, such as <code class="docutils literal notranslate"><span class="pre">Mandelbrot</span></code>
from <code class="docutils literal notranslate"><span class="pre">bench_avx.py</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="n">runtests</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">bench</span> <span class="n">bench_avx</span><span class="o">.</span><span class="n">Mandelbrot</span>
</pre></div>
</div>
<p>Compare change in benchmark results to another version/commit/branch:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="n">runtests</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">bench</span><span class="o">-</span><span class="n">compare</span> <span class="n">v1</span><span class="o">.</span><span class="mf">6.2</span> <span class="n">bench_core</span>
<span class="n">python</span> <span class="n">runtests</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">bench</span><span class="o">-</span><span class="n">compare</span> <span class="mi">8</span><span class="n">bf4e9b</span> <span class="n">bench_core</span>
<span class="n">python</span> <span class="n">runtests</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">bench</span><span class="o">-</span><span class="n">compare</span> <span class="n">master</span> <span class="n">bench_core</span>
</pre></div>
</div>
<p>All of the commands above display the results in plain text in
the console, and the results are not saved for comparison with
future commits. For greater control, a graphical view, and to
have results saved for future comparison you can run ASV commands
(record results and generate HTML):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">cd</span> <span class="n">benchmarks</span>
<span class="n">asv</span> <span class="n">run</span> <span class="o">-</span><span class="n">n</span> <span class="o">-</span><span class="n">e</span> <span class="o">--</span><span class="n">python</span><span class="o">=</span><span class="n">same</span>
<span class="n">asv</span> <span class="n">publish</span>
<span class="n">asv</span> <span class="n">preview</span>
</pre></div>
</div>
<p>More on how to use <code class="docutils literal notranslate"><span class="pre">asv</span></code> can be found in <a class="reference external" href="https://asv.readthedocs.io/">ASV documentation</a>
Command-line help is available as usual via <code class="docutils literal notranslate"><span class="pre">asv</span> <span class="pre">--help</span></code> and
<code class="docutils literal notranslate"><span class="pre">asv</span> <span class="pre">run</span> <span class="pre">--help</span></code>.</p>
</div>
<div class="section" id="writing-benchmarks">
<h2>Writing benchmarks<a class="headerlink" href="#writing-benchmarks" title="Permalink to this headline">¶</a></h2>
<p>See <a class="reference external" href="https://asv.readthedocs.io/">ASV documentation</a> for basics on how to write benchmarks.</p>
<p>Some things to consider:</p>
<ul class="simple">
<li><p>The benchmark suite should be importable with any NumPy version.</p></li>
<li><p>The benchmark parameters etc. should not depend on which NumPy version
is installed.</p></li>
<li><p>Try to keep the runtime of the benchmark reasonable.</p></li>
<li><p>Prefer ASV’s <code class="docutils literal notranslate"><span class="pre">time_</span></code> methods for benchmarking times rather than cooking up
time measurements via <code class="docutils literal notranslate"><span class="pre">time.clock</span></code>, even if it requires some juggling when
writing the benchmark.</p></li>
<li><p>Preparing arrays etc. should generally be put in the <code class="docutils literal notranslate"><span class="pre">setup</span></code> method rather
than the <code class="docutils literal notranslate"><span class="pre">time_</span></code> methods, to avoid counting preparation time together with
the time of the benchmarked operation.</p></li>
<li><p>Be mindful that large arrays created with <code class="docutils literal notranslate"><span class="pre">np.empty</span></code> or <code class="docutils literal notranslate"><span class="pre">np.zeros</span></code> might
not be allocated in physical memory until the memory is accessed. If this is
desired behaviour, make sure to comment it in your setup function. If
you are benchmarking an algorithm, it is unlikely that a user will be
executing said algorithm on a newly created empty/zero array. One can force
pagefaults to occur in the setup phase either by calling <code class="docutils literal notranslate"><span class="pre">np.ones</span></code> or
<code class="docutils literal notranslate"><span class="pre">arr.fill(value)</span></code> after creating the array,</p></li>
</ul>
</div>
</div>


              </div>
              
              
              <div class='prev-next-bottom'>
                
    <a class='left-prev' id="prev-link" href="dev/development_advanced_debugging.html" title="previous page">Advanced debugging tools</a>
    <a class='right-next' id="next-link" href="dev/releasing.html" title="next page">Releasing a Version</a>

              </div>
              
          </main>
          

      </div>
    </div>

    
  <script src="_static/js/index.d3f166471bb80abb5163.js"></script>


    <footer class="footer mt-5 mt-md-0">
  <div class="container">
    <p>
          &copy; Copyright 2008-2021, The SciPy community.<br/>
        Last updated on Feb 18, 2021.<br/>
        Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.5.0.<br/>
    </p>
  </div>
</footer>
  </body>
</html>